{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<h1>\n",
        "<h1>APM 53674: ALTeGraD</h1>\n",
        "<h2>Lab Session 1: Neural Machine Translation and Language Modeling</h2>\n",
        "<h4>Lecture: Prof. Michalis Vazirgiannis<br>\n",
        "Lab: Dr. Hadi Abdine and Yang Zhang</h4>\n",
        "<h5>Monday, September 30, 2025</h5>\n",
        "<br>\n",
        "</center>\n",
        "\n",
        "<hr style=\"border:10px solid gray\"> </hr>\n",
        "<p style=\"text-align: justify;\">\n",
        "This handout includes theoretical introductions, <font color='blue'>coding tasks</font> and <font color='red'>questions</font>. Before the deadline, you should submit <a href='https://forms.gle/9dyaes6dimfvyjwq6' target=\"_blank\">here</a> a <B>.ipynb</B> file named <b>Lastname_Firstname.ipynb</b> containing your notebook (with the gaps filled and your answers to the questions). Your answers should be well constructed and well justified. They should not repeat the question or generalities in the handout. When relevant, you are welcome to include figures, equations and tables derived from your own computations, theoretical proofs or qualitative explanations. One submission is required for each student. The deadline for this lab is <b>October 05\n",
        ", 2025 11:59 PM</b>. No extension will be granted. Late policy is as follows: ]0, 24] hours late → -5 pts; ]24, 48] hours late → -10 pts; > 48 hours late → not graded (zero).\n",
        "</p>\n",
        "<hr style=\"border:5px solid gray\"> </hr>\n"
      ],
      "metadata": {
        "id": "PwXvz16rv753"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Neural Machine Translation</b></h2>"
      ],
      "metadata": {
        "id": "002zIWSTw46F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCJvlnvsKALE"
      },
      "source": [
        "<h3><b>1. Learning Objective:</b></h2>\n",
        "<p style=\"text-align: justify;\">\n",
        "In this lab, you will learn about sequence to sequence (seq2seq) architectures.\n",
        "More precisely, we will implement the Neural Machine Translation (NMT) model described in <a href='https://arxiv.org/abs/1508.04025'>[Luong et al., 2015]</a> using Python 3.6 and PyTorch (the latest version).\n",
        "The only difference is that we will be using non-stacked RNNs, whereas <a href='https://arxiv.org/abs/1508.04025'>[Luong et al., 2015]</a> uses stacked RNNs.\n",
        "\n",
        "We will train our model on the task of English to French translation, using a set of sentence pairs from <a href='http://www.manythings.org/anki/'>http://www.manythings.org/anki/</a>, originally extracted from the Tatoeba project: <a href='https://tatoeba.org/eng/'>https://tatoeba.org/eng/</a>.\n",
        "\n",
        "Our dataset features 136,521 pairs for training and 34,130 pairs for testing, which is quite small, but enough for the purpose of this lab.\n",
        "The average size of a source sentence is 7.6 while the average size of a target sentence is 8.3.\n",
        "\n",
        "$\\underline{\\textbf{Note}}$: the pairs have already been preprocessed.\n",
        "Each sentence was turned into a list of integers starting from 4.\n",
        "The integers correspond to indexes in the source and target vocabularies, that have been constructed from the training set, and in which the most frequent words have index 4.\n",
        "0, 1, 2 and 3 are reserved respectively for the padding, out-of-vocabulary, start of sentence, and end of sentence special tokens.\n",
        "\n",
        "<h3><b>2. Recurrent Neural Networks:</b></h3>\n",
        "<p style=\"text-align: justify;\">\n",
        "\n",
        "While CNNs are good at dealing with grids, RNNs were specifically developed to be used with sequences.\n",
        "As shown in Fig. 1, a RNN can be viewed as a chain of simple neural layers that share the same parameters.\n",
        "From a high level, a RNN is fed an ordered list of input vectors $\\big\\{x_{1},...,x_{T}\\big\\}$ as well as an initial hidden state $h_{0}$ initialized to all zeros, and returns an ordered list of hidden states $\\big\\{h_{1},...,h_{T}\\big\\}$, as well as an ordered list of output vectors $\\big\\{y_{1},...,y_{T}\\big\\}$.\n",
        "The hidden states may serve as input to the RNN units above in the case of a stacked architecture, or directly be used as they are (e.g., by the attention mechanism).\n",
        "The hidden states correspond more or less to the \"short-term\" memory of the network.\n",
        "<center>\n",
        "<table><tr>\n",
        "<td> <img src='https://1drv.ms/i/c/ae69638675180117/UQQXARh1hmNpIICuu4QBAAAAAMrZ9Edq70cBsjo?width=498&height=246' alt=\"Drawing\" width= '500px'/> </td>\n",
        "<td> <img src=\"https://1drv.ms/i/c/ae69638675180117/UQQXARh1hmNpIICuvIQBAAAAAJVN-1WBTh55QtY?width=1336&height=733\" alt=\"Drawing\" width='500px'/> </td>\n",
        "</tr></table>\n",
        "\n",
        "<b>Figure 1:</b> Left: 3 steps of an unrolled RNN (adapted from <a href='http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/'>Denny Britz' blog</a>). Right: 3 steps of an unrolled stacked RNN.\n",
        "The hidden states at a given position flow vertically through the RNN layers. On both sides, each circle represents a  RNN unit. </a><br>\n",
        "</center>\n",
        "\n",
        "<h3><b>3. Sequence-to-sequence architecture:</b></h3>\n",
        "<p style=\"text-align: justify;\">\n",
        "Our input and output are sequences of words, respectively $x = \\big(x_1, \\dots ,x_{T_x}\\big)$ and $y = \\big(y_1, \\dots ,y_{T_y}\\big)$.\n",
        "$x$ and $y$ are usually referred to as the $\\textit{source}$ and $\\textit{target}$ sentences.\n",
        "<h4><b>3.1. Encoder</b></h4>\n",
        "<p style=\"text-align: justify;\">\n",
        "Our encoder is a non-stacked unidirectional RNN with GRU units (see the appendix for details about the GRU.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB6pvLvlKbtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa240b4-a71c-4adb-e164-d5e42cac7acc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from nltk import word_tokenize\n",
        "import sys\n",
        "import json\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 1: </b><br>\n",
        "Fill the gaps in the $\\texttt{forward}$ function of the $\\texttt{Encoder}$ class.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "LNLFXbJu7Kcp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc8cQTFkKmif"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    to be passed the entire source sequence at once\n",
        "    we use padding_idx in nn.Embedding so that the padding vector does not take gradient (always zero)\n",
        "    https://pytorch.org/docs/stable/nn.html#gru\n",
        "    '''\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, padding_idx):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx)\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        word_vectors = self.embedding(input) # fill the gap\n",
        "        hs, _ = self.rnn(word_vectors)  # fill the gap # (seq,batch,feat)\n",
        "        return hs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4><b>3.2. Decoder</b></h4>\n",
        "<p style=\"text-align: justify;\">\n",
        "Our decoder is a non-stacked unidirectional RNN.\n",
        "It is a neural language model conditioned not only on the previously generated target words but also on the source sentence.\n",
        "More precisely, it generates the target sentence $y=(y_1,\\dots,y_{T_y})$ one word $y_t$ at a time based on the distribution:\n",
        "\n",
        "\\begin{equation}\n",
        "P\\big[y_t|\\{y_{1},...,y_{t-1}\\},c_t\\big] = \\mathrm{softmax}\\big(W_s\\tilde{h}_t\\big)\n",
        "\\end{equation}\n",
        "\n",
        "where $\\tilde{h}_t$, the \\textit{attentional} hidden state, is computed as (biases are not shown for simplicity):\n",
        "\n",
        "\\begin{equation}\n",
        "\\tilde{h}_t = \\mathrm{tanh}\\big(W_c\\big[c_t;h_t\\big]\\big)\n",
        "\\end{equation}\n",
        "\n",
        " $h_t$ is the $t^{th}$ hidden state of the decoder, $c_t$ is the source context vector, and $\\big[;\\big]$ denotes concatenation. $W_s$ and $W_c$ are matrices of trainable parameters.\n",
        "\n",
        "$\\textbf{Note:}$ while all the inputs of the encoder (i.e., all the words of the input sentence) are known at encoding time, the decoder generates one target word at a time, and uses as input at time $t$ its prediction from time $t-1$.\n",
        "\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 2: </b><br>\n",
        "Fill the gaps in the $\\texttt{forward}$ function of the $\\texttt{Decoder}$ class.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "gZgoCyV27q65"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7tLaq4PK90q"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''to be used one timestep at a time\n",
        "       see https://pytorch.org/docs/stable/nn.html#gru'''\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, padding_idx):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx)\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim)\n",
        "        self.ff_concat = nn.Linear(2*hidden_dim,hidden_dim)\n",
        "        self.predict = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input, source_context, h):\n",
        "        word_vector = self.embedding(input) # fill the gap # (1,batch) -> (1,batch,feat)\n",
        "        output, h = self.rnn(word_vector, h) # fill the gap # (1,batch,feat)\n",
        "        tilde_h = torch.tanh(self.ff_concat(torch.cat([source_context, h], dim=-1))) # fill the gap # (1,batch,2*feat) -> (1,batch,feat)\n",
        "        prediction = self.predict(tilde_h) # (1,batch,feat) -> (1,batch,vocab)\n",
        "\n",
        "        return prediction, h"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4><b>3.3. Global attention mechanism</b></h4>\n",
        "<p style=\"text-align: justify;\">\n",
        "The context vector $c_t$ is computed as a weighted sum of the encoder's hidden states $\\bar{h}_i$.\n",
        "The vector of weights $\\alpha_{t}$ is obtained by applying a softmax to the output of an $\\textit{alignment}$ operation ($\\texttt{score()}$) between the current target hidden state $h_t$ and all source hidden states $\\bar{h}_{i}$'s.\n",
        "$\\alpha_{t}$ indicates which words in the source sentence are the most likely to help in predicting the next word.\n",
        "$\\texttt{score()}$ can in theory be any comparison function.\n",
        "In our implementation, we will use the $\\texttt{concat}$ attention formulation of <a href='https://arxiv.org/abs/1508.04025'>[Luong et al., 2015]</a> (see section 3.1 of the paper).\n",
        "An overview is provided in Fig. 2.  at a time, and uses as input at time $t$ its prediction from time $t-1$.\n",
        "<center>\n",
        "<img width='800px' src='https://1drv.ms/i/c/ae69638675180117/UQQXARh1hmNpIICutoQBAAAAAMg4GcKQUg3VOR8?width=1836&height=874' />\n",
        "<br>\n",
        "<b>Figure 2:</b>Summary of the $\\textit{global attention}$ mechanism <a href='https://arxiv.org/abs/1508.04025'>[Luong et al., 2015]</a> <br>\n",
        "</center>\n",
        "\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 3: </b><br>\n",
        "Fill the gaps in the $\\texttt{forward}$ function of the $\\texttt{seq2seqAtt}$ class.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "0mE7IkYx8Kjl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwUAUDL4KmoM"
      },
      "source": [
        "class seq2seqAtt(nn.Module):\n",
        "    '''\n",
        "    concat global attention a la Luong et al. 2015 (subsection 3.1)\n",
        "    https://arxiv.org/pdf/1508.04025.pdf\n",
        "    '''\n",
        "    def __init__(self, hidden_dim, hidden_dim_s, hidden_dim_t):\n",
        "        super(seq2seqAtt, self).__init__()\n",
        "        self.ff_concat = nn.Linear(hidden_dim_s+hidden_dim_t,hidden_dim)\n",
        "        self.ff_score = nn.Linear(hidden_dim,1,bias=False) # just a dot product here\n",
        "\n",
        "    def forward(self,target_h,source_hs):\n",
        "        target_h_rep = target_h.repeat(source_hs.size(0),1,1) # (1,batch,feat) -> (seq,batch,feat)\n",
        "        concat_output = self.ff_concat(torch.cat([target_h_rep, source_hs], dim=-1)) # fill the gap # source_hs is (seq,batch,feat)\n",
        "        scores = self.ff_score(torch.tanh(concat_output)) # (seq,batch,feat) -> (seq,batch,1)\n",
        "        scores = scores.squeeze(dim=2) # (seq,batch,1) -> (seq,batch). dim=2 because we don't want to squeeze the batch dim if batch size = 1\n",
        "        norm_scores = torch.softmax(scores, 0) # attention weights\n",
        "        source_hs_p = source_hs.permute((2,0,1)) # (seq,batch,feat) -> (feat,seq,batch)\n",
        "        weighted_source_hs = (norm_scores * source_hs_p) # (seq,batch) * (feat,seq,batch) (* checks from right to left that the dimensions match)\n",
        "        ct = torch.sum(weighted_source_hs.permute((1,2,0)),0,keepdim=True) # (feat,seq,batch) -> (seq,batch,feat) -> (1,batch,feat); keepdim otherwise sum squeezes\n",
        "        return ct, norm_scores.squeeze(1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>4. Training and Evaluation:</b></h3>\n",
        "<p style=\"text-align: justify;\">\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 4: </b><br>\n",
        "Fill the gaps in the $\\texttt{forward}$ function of the $\\texttt{seq2seqModel}$ class.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "nLurQq5qABAz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYX0K3dNK-c9"
      },
      "source": [
        "class seq2seqModel(nn.Module):\n",
        "    '''the full seq2seq model'''\n",
        "    ARGS = ['vocab_s','source_language','vocab_t_inv','embedding_dim_s','embedding_dim_t',\n",
        "     'hidden_dim_s','hidden_dim_t','hidden_dim_att','do_att','padding_token',\n",
        "     'oov_token','sos_token','eos_token','max_size']\n",
        "    def __init__(self, vocab_s, source_language, vocab_t_inv, embedding_dim_s, embedding_dim_t,\n",
        "                 hidden_dim_s, hidden_dim_t, hidden_dim_att, do_att, padding_token,\n",
        "                 oov_token, sos_token, eos_token, max_size):\n",
        "        super(seq2seqModel, self).__init__()\n",
        "        self.vocab_s = vocab_s\n",
        "        self.source_language = source_language\n",
        "        self.vocab_t_inv = vocab_t_inv\n",
        "        self.embedding_dim_s = embedding_dim_s\n",
        "        self.embedding_dim_t = embedding_dim_t\n",
        "        self.hidden_dim_s = hidden_dim_s\n",
        "        self.hidden_dim_t = hidden_dim_t\n",
        "        self.hidden_dim_att = hidden_dim_att\n",
        "        self.do_att = do_att # should attention be used?\n",
        "        self.padding_token = padding_token\n",
        "        self.oov_token = oov_token\n",
        "        self.sos_token = sos_token\n",
        "        self.eos_token = eos_token\n",
        "        self.max_size = max_size\n",
        "\n",
        "        self.max_source_idx = max(list(vocab_s.values()))\n",
        "        print('max source index',self.max_source_idx)\n",
        "        print('source vocab size',len(vocab_s))\n",
        "\n",
        "        self.max_target_idx = max([int(elt) for elt in list(vocab_t_inv.keys())])\n",
        "        print('max target index',self.max_target_idx)\n",
        "        print('target vocab size',len(vocab_t_inv))\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.encoder = Encoder(self.max_source_idx+1,self.embedding_dim_s,self.hidden_dim_s,self.padding_token).to(self.device)\n",
        "        self.decoder = Decoder(self.max_target_idx+1,self.embedding_dim_t,self.hidden_dim_t,self.padding_token).to(self.device)\n",
        "\n",
        "        if self.do_att:\n",
        "            self.att_mech = seq2seqAtt(self.hidden_dim_att,self.hidden_dim_s,self.hidden_dim_t).to(self.device)\n",
        "\n",
        "    def my_pad(self,my_list):\n",
        "        '''my_list is a list of tuples of the form [(tensor_s_1,tensor_t_1),...,(tensor_s_batch,tensor_t_batch)]\n",
        "        the <eos> token is appended to each sequence before padding\n",
        "        https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pad_sequence'''\n",
        "        batch_source = pad_sequence([torch.cat((elt[0],torch.LongTensor([self.eos_token]))) for elt in my_list],batch_first=True,padding_value=self.padding_token)\n",
        "        batch_target = pad_sequence([torch.cat((elt[1],torch.LongTensor([self.eos_token]))) for elt in my_list],batch_first=True,padding_value=self.padding_token)\n",
        "        return batch_source,batch_target\n",
        "\n",
        "    def forward(self,input,max_size,is_prod):\n",
        "\n",
        "        if is_prod:\n",
        "            input = input.unsqueeze(1) # (seq) -> (seq,1) 1D input <=> we receive just one sentence as input (predict/production mode)\n",
        "\n",
        "        current_batch_size = input.size(1)\n",
        "\n",
        "        # fill the gap #\n",
        "        # use the encoder\n",
        "        source_hs = self.encoder(input) # (seq,batch)/(seq,1) -> (seq,batch,feat)/(seq,1,feat)\n",
        "\n",
        "        # = = = decoder part (one timestep at a time)  = = =\n",
        "\n",
        "        target_h = torch.zeros(size=(1,current_batch_size,self.hidden_dim_t)).to(self.device) # init (1,batch,feat)\n",
        "\n",
        "        # fill the gap #\n",
        "        # (initialize target_input with the proper token)\n",
        "        target_input = torch.LongTensor([self.sos_token]).repeat(current_batch_size).unsqueeze(0).to(self.device) # init (1,batch)\n",
        "\n",
        "        pos = 0\n",
        "        eos_counter = 0\n",
        "        logits = []\n",
        "        weights = []\n",
        "\n",
        "        while True:\n",
        "\n",
        "            if self.do_att:\n",
        "                source_context = self.att_mech(target_h,source_hs) # (1,batch,feat)\n",
        "                weights.append(source_context[1].tolist()) # attention weights\n",
        "                source_context = source_context[0]\n",
        "            else:\n",
        "                source_context = source_hs[-1,:,:].unsqueeze(0) # (1,batch,feat) last hidden state of encoder\n",
        "\n",
        "            # fill the gap #\n",
        "            # use the decoder\n",
        "            prediction, target_h = self.decoder(target_input, source_context, target_h)\n",
        "\n",
        "            logits.append(prediction) # (1,batch,vocab)\n",
        "\n",
        "            # fill the gap #\n",
        "            # get the next input to pass the decoder\n",
        "            target_input = prediction.argmax(-1)\n",
        "\n",
        "            eos_counter += torch.sum(target_input==self.eos_token).item()\n",
        "\n",
        "            pos += 1\n",
        "            if pos>=max_size or (eos_counter == current_batch_size and is_prod):\n",
        "                break\n",
        "\n",
        "        to_return = torch.cat(logits,0) # logits is a list of tensors -> (seq,batch,vocab)\n",
        "\n",
        "        if is_prod:\n",
        "            to_return = to_return.squeeze(dim=1) # (seq,vocab)\n",
        "\n",
        "        return to_return, weights\n",
        "\n",
        "    def fit(self, trainingDataset, testDataset, lr, batch_size, n_epochs, patience):\n",
        "\n",
        "        parameters = [p for p in self.parameters() if p.requires_grad]\n",
        "\n",
        "        optimizer = optim.Adam(parameters, lr=lr)\n",
        "\n",
        "        criterion = torch.nn.CrossEntropyLoss(ignore_index=self.padding_token) # the softmax is inside the loss!\n",
        "\n",
        "        # https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
        "        # we pass a collate function to perform padding on the fly, within each batch\n",
        "        # this is better than truncation/padding at the dataset level\n",
        "        train_loader = data.DataLoader(trainingDataset, batch_size=batch_size,\n",
        "                                       shuffle=True, collate_fn=self.my_pad) # returns (batch,seq)\n",
        "\n",
        "        test_loader = data.DataLoader(testDataset, batch_size=512,\n",
        "                                      collate_fn=self.my_pad)\n",
        "\n",
        "        tdqm_dict_keys = ['loss', 'test loss']\n",
        "        tdqm_dict = dict(zip(tdqm_dict_keys,[0.0,0.0]))\n",
        "\n",
        "        patience_counter = 1\n",
        "        patience_loss = 99999\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "\n",
        "            with tqdm(total=len(train_loader),unit_scale=True,postfix={'loss':0.0,'test loss':0.0},\n",
        "                      desc=\"Epoch : %i/%i\" % (epoch, n_epochs-1),ncols=100) as pbar:\n",
        "                for loader_idx, loader in enumerate([train_loader, test_loader]):\n",
        "                    total_loss = 0\n",
        "                    # set model mode (https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "                    if loader_idx == 0:\n",
        "                        self.train()\n",
        "                    else:\n",
        "                        self.eval()\n",
        "                    for i, (batch_source,batch_target) in enumerate(loader):\n",
        "                        batch_source = batch_source.transpose(1,0).to(self.device) # RNN needs (seq,batch,feat) but loader returns (batch,seq)\n",
        "                        batch_target = batch_target.transpose(1,0).to(self.device) # (seq,batch)\n",
        "\n",
        "                        # are we using the model in production / as an API?\n",
        "                        is_prod = len(batch_source.shape)==1 # if False, 2D input (seq,batch), i.e., train or test\n",
        "\n",
        "                        if is_prod:\n",
        "                            max_size = self.max_size\n",
        "                            self.eval()\n",
        "                        else:\n",
        "                            max_size = batch_target.size(0) # no need to continue generating after we've exceeded the length of the longest ground truth sequence\n",
        "\n",
        "                        unnormalized_logits = self.forward(batch_source,max_size,is_prod)[0]\n",
        "\n",
        "                        sentence_loss = criterion(unnormalized_logits.flatten(end_dim=1),batch_target.flatten())\n",
        "\n",
        "                        total_loss += sentence_loss.item()\n",
        "\n",
        "                        tdqm_dict[tdqm_dict_keys[loader_idx]] = total_loss/(i+1)\n",
        "\n",
        "                        pbar.set_postfix(tdqm_dict)\n",
        "\n",
        "                        if loader_idx == 0:\n",
        "                            optimizer.zero_grad() # flush gradient attributes\n",
        "                            sentence_loss.backward() # compute gradients\n",
        "                            optimizer.step() # update\n",
        "                            pbar.update(1)\n",
        "\n",
        "            if total_loss > patience_loss:\n",
        "                patience_counter += 1\n",
        "            else:\n",
        "                patience_loss = total_loss\n",
        "                patience_counter = 1 # reset\n",
        "\n",
        "            if patience_counter>patience:\n",
        "                break\n",
        "\n",
        "    def sourceNl_to_ints(self,source_nl):\n",
        "        '''converts natural language source sentence into source integers'''\n",
        "        source_nl_clean = source_nl.lower().replace(\"'\",' ').replace('-',' ')\n",
        "        source_nl_clean_tok = word_tokenize(source_nl_clean,self.source_language)\n",
        "        source_ints = [int(self.vocab_s[elt]) if elt in self.vocab_s else \\\n",
        "                       self.oov_token for elt in source_nl_clean_tok]\n",
        "\n",
        "        source_ints = torch.LongTensor(source_ints).to(self.device)\n",
        "        return source_ints\n",
        "\n",
        "    def targetInts_to_nl(self,target_ints):\n",
        "        '''converts integer target sentence into target natural language'''\n",
        "        return ['<PAD>' if elt==self.padding_token else '<OOV>' if elt==self.oov_token \\\n",
        "                else '<EOS>' if elt==self.eos_token else '<SOS>' if elt==self.sos_token\\\n",
        "                else self.vocab_t_inv[elt] for elt in target_ints]\n",
        "\n",
        "    def predict(self,source_nl):\n",
        "        source_ints = self.sourceNl_to_ints(source_nl)\n",
        "        logits = self.forward(source_ints,self.max_size,True) # (seq) -> (<=max_size,vocab)\n",
        "        target_ints = logits[0].argmax(-1).squeeze() # (<=max_size,1) -> (<=max_size)\n",
        "        target_nl = self.targetInts_to_nl(target_ints.tolist())\n",
        "        return ' '.join(target_nl), logits[1]\n",
        "\n",
        "    def save(self,path_to_file):\n",
        "        attrs = {attr:getattr(self,attr) for attr in self.ARGS}\n",
        "        attrs['state_dict'] = self.state_dict()\n",
        "        torch.save(attrs,path_to_file)\n",
        "\n",
        "    @classmethod # a class method does not see the inside of the class (a static method does not take self as first argument)\n",
        "    def load(cls,path_to_file):\n",
        "        attrs = torch.load(path_to_file, map_location=lambda storage, loc: storage) # allows loading on CPU a model trained on GPU, see https://discuss.pytorch.org/t/on-a-cpu-device-how-to-load-checkpoint-saved-on-gpu-device/349/6\n",
        "        state_dict = attrs.pop('state_dict')\n",
        "        new = cls(**attrs) # * list and ** names (dict) see args and kwargs\n",
        "        new.load_state_dict(state_dict)\n",
        "        return new"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the data and the pretrained model:"
      ],
      "metadata": {
        "id": "md-HH53wAq3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "\n",
        "urllib.request.urlretrieve(\"https://nuage.lix.polytechnique.fr/public.php/dav/files/FLttXTmeFSDNx7H\", \"data.zip\")\n",
        "urllib.request.urlretrieve(\"https://nuage.lix.polytechnique.fr/public.php/dav/files/6btZHdtYnyAAH3x\", \"pretrained_moodle.pt\")\n",
        "!unzip data.zip\n",
        "\n",
        "path_to_data = './data/'\n",
        "path_to_save_models = './'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8v4T_TPnVh9",
        "outputId": "461bb43c-4083-4b03-9335-9d03e5df0311"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "replace __MACOSX/._data? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the dataloader:"
      ],
      "metadata": {
        "id": "AmBgproQAv8_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZCiFl61LPQj"
      },
      "source": [
        "class Dataset(data.Dataset):\n",
        "  def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.pairs) # total nb of observations\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        source, target = self.pairs[idx] # one observation\n",
        "        return torch.LongTensor(source), torch.LongTensor(target)\n",
        "\n",
        "def load_pairs(train_or_test):\n",
        "\n",
        "    with open(path_to_data + 'pairs_' + train_or_test + '_ints.txt', 'r', encoding='utf-8') as file:\n",
        "        pairs_tmp = file.read().splitlines()\n",
        "    pairs_tmp = [elt.split('\\t') for elt in pairs_tmp]\n",
        "    pairs_tmp = [[[int(eltt) for eltt in elt[0].split()],[int(eltt) for eltt in \\\n",
        "                  elt[1].split()]] for elt in pairs_tmp]\n",
        "    return pairs_tmp"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 5: </b><br>\n",
        "Check that your implementation is correct by running $\\texttt{the following cell}$ for a few epochs and verifying that the loss decreases.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "a1yDxMlvA1yH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSZ-cvSuLQVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8aef028-7bf0-484a-849d-9c8a85bc7ef2"
      },
      "source": [
        "do_att = True # should always be set to True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pairs_train = load_pairs('train')\n",
        "pairs_test = load_pairs('test')\n",
        "\n",
        "with open(path_to_data + 'vocab_source.json','r') as file:\n",
        "    vocab_source = json.load(file) # word -> index\n",
        "\n",
        "with open(path_to_data + 'vocab_target.json','r') as file:\n",
        "    vocab_target = json.load(file) # word -> index\n",
        "\n",
        "vocab_target_inv = {v:k for k,v in vocab_target.items()} # index -> word\n",
        "print('data loaded')\n",
        "training_set = Dataset(pairs_train)\n",
        "test_set = Dataset(pairs_test)\n",
        "print('data prepared')\n",
        "print('= = = attention-based model?:',str(do_att),'= = =')\n",
        "\n",
        "model = seq2seqModel(vocab_s=vocab_source,\n",
        "                      source_language='english',\n",
        "                      vocab_t_inv=vocab_target_inv,\n",
        "                      embedding_dim_s=40,\n",
        "                      embedding_dim_t=40,\n",
        "                      hidden_dim_s=30,\n",
        "                      hidden_dim_t=30,\n",
        "                      hidden_dim_att=20,\n",
        "                      do_att=do_att,\n",
        "                      padding_token=0,\n",
        "                      oov_token=1,\n",
        "                      sos_token=2,\n",
        "                      eos_token=3,\n",
        "                      max_size=30).to(device) # max size of generated sentence in prediction mode\n",
        "\n",
        "model.fit(training_set,test_set,lr=0.001,batch_size=64,n_epochs=20,patience=2)\n",
        "model.save(path_to_save_models + 'my_model.pt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data loaded\n",
            "data prepared\n",
            "= = = attention-based model?: True = = =\n",
            "max source index 5281\n",
            "source vocab size 5278\n",
            "max target index 7459\n",
            "target vocab size 7456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch : 0/19: 100%|██████████████████| 2.13k/2.13k [01:59<00:00, 17.9it/s, loss=5.2, test loss=4.66]\n",
            "Epoch : 1/19: 100%|█████████████████| 2.13k/2.13k [01:55<00:00, 18.4it/s, loss=4.45, test loss=4.23]\n",
            "Epoch : 2/19: 100%|█████████████████| 2.13k/2.13k [01:56<00:00, 18.3it/s, loss=4.03, test loss=3.87]\n",
            "Epoch : 3/19: 100%|█████████████████| 2.13k/2.13k [01:56<00:00, 18.4it/s, loss=3.73, test loss=3.65]\n",
            "Epoch : 4/19: 100%|█████████████████| 2.13k/2.13k [01:57<00:00, 18.2it/s, loss=3.53, test loss=3.47]\n",
            "Epoch : 5/19: 100%|█████████████████| 2.13k/2.13k [01:54<00:00, 18.6it/s, loss=3.37, test loss=3.35]\n",
            "Epoch : 6/19: 100%|█████████████████| 2.13k/2.13k [01:56<00:00, 18.4it/s, loss=3.24, test loss=3.25]\n",
            "Epoch : 7/19: 100%|█████████████████| 2.13k/2.13k [01:54<00:00, 18.6it/s, loss=3.14, test loss=3.16]\n",
            "Epoch : 8/19: 100%|██████████████████| 2.13k/2.13k [01:54<00:00, 18.6it/s, loss=3.05, test loss=3.1]\n",
            "Epoch : 9/19: 100%|█████████████████| 2.13k/2.13k [01:54<00:00, 18.6it/s, loss=2.98, test loss=3.05]\n",
            "Epoch : 10/19: 100%|████████████████| 2.13k/2.13k [01:54<00:00, 18.6it/s, loss=2.92, test loss=3.01]\n",
            "Epoch : 11/19: 100%|████████████████| 2.13k/2.13k [01:53<00:00, 18.8it/s, loss=2.86, test loss=2.95]\n",
            "Epoch : 12/19: 100%|████████████████| 2.13k/2.13k [01:52<00:00, 19.0it/s, loss=2.82, test loss=2.91]\n",
            "Epoch : 13/19: 100%|████████████████| 2.13k/2.13k [01:53<00:00, 18.8it/s, loss=2.77, test loss=2.92]\n",
            "Epoch : 14/19: 100%|████████████████| 2.13k/2.13k [01:52<00:00, 18.9it/s, loss=2.73, test loss=2.85]\n",
            "Epoch : 15/19: 100%|█████████████████| 2.13k/2.13k [01:53<00:00, 18.8it/s, loss=2.7, test loss=2.82]\n",
            "Epoch : 16/19: 100%|█████████████████| 2.13k/2.13k [01:54<00:00, 18.6it/s, loss=2.67, test loss=2.8]\n",
            "Epoch : 17/19: 100%|████████████████| 2.13k/2.13k [01:54<00:00, 18.7it/s, loss=2.64, test loss=2.79]\n",
            "Epoch : 18/19: 100%|████████████████| 2.13k/2.13k [01:53<00:00, 18.9it/s, loss=2.61, test loss=2.75]\n",
            "Epoch : 19/19: 100%|████████████████| 2.13k/2.13k [01:53<00:00, 18.8it/s, loss=2.59, test loss=2.74]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 6: </b><br>\n",
        "Run the following cell using the pre-trained weights.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "WjzknQ0EBTIF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwUInZMyQzci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe326fb-94db-49a1-827c-9dacbb26028f"
      },
      "source": [
        "pretrained_model = seq2seqModel.load(path_to_save_models + 'pretrained_moodle.pt')\n",
        "# model = seq2seqModel.load(path_to_save_models + 'my_model.pt')\n",
        "# model.eval()\n",
        "to_test = ['I am a student.',\n",
        "            'I have a red car.',  # inversion captured\n",
        "            'I love playing video games.',\n",
        "            'This river is full of fish.', # plein vs pleine (accord)\n",
        "            'The fridge is full of food.',\n",
        "            'The cat fell asleep on the mat.',\n",
        "            'my brother likes pizza.', # pizza is translated to 'la pizza'\n",
        "            'I did not mean to hurt you', # translation of mean in context\n",
        "            'She is so mean',\n",
        "            'Help me pick out a tie to go with this suit!', # right translation\n",
        "            \"I can't help but smoking weed\", # this one and below: hallucination\n",
        "            'The kids were playing hide and seek',\n",
        "            'The cat fell asleep in front of the fireplace']\n",
        "\n",
        "for elt in to_test:\n",
        "    print('= = = = = \\n','%s -> %s' % (elt, pretrained_model.predict(elt)[0]))\n",
        "    # print('= = = = = \\n','%s -> %s' % (elt, model.predict(elt)[0]))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max source index 5281\n",
            "source vocab size 5278\n",
            "max target index 7459\n",
            "target vocab size 7456\n",
            "= = = = = \n",
            " I am a student. -> je suis étudiant . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "= = = = = \n",
            " I have a red car. -> j ai une voiture rouge . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "= = = = = \n",
            " I love playing video games. -> j adore jouer à jeux jeux jeux vidéo . . . . . . . . . . . . . . . . . . . . . .\n",
            "= = = = = \n",
            " This river is full of fish. -> cette rivière est pleine de poisson . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "= = = = = \n",
            " The fridge is full of food. -> le frigo est plein de nourriture . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "= = = = = \n",
            " The cat fell asleep on the mat. -> le chat s est endormi sur le tapis . . . . . . . . . . . . . . . . . . . . . .\n",
            "= = = = = \n",
            " my brother likes pizza. -> mon frère aime la pizza . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "= = = = = \n",
            " I did not mean to hurt you -> je n ai pas voulu intention de blesser blesser blesser blesser blesser blesser . blesser . blesser . . . . . . . . . . . . .\n",
            "= = = = = \n",
            " She is so mean -> elle est tellement méchant méchant . <EOS>\n",
            "= = = = = \n",
            " Help me pick out a tie to go with this suit! -> aidez moi à chercher une cravate pour aller avec ceci ! ! ! ! ! ! ! ! ! ! ! ! ! ! <EOS>\n",
            "= = = = = \n",
            " I can't help but smoking weed -> je ne peux pas empêcher de de fumer fumer fumer fumer fumer fumer fumer fumer fumer fumer urgence urgence urgence urgence urgence urgence . urgence urgence . urgence urgence .\n",
            "= = = = = \n",
            " The kids were playing hide and seek -> les enfants jouent cache cache cache cache caché caché caché caché caché caché caché caché caché caché caché caché caché caché caché dentifrice perdre caché risques rapide caché risques éveillés\n",
            "= = = = = \n",
            " The cat fell asleep in front of the fireplace -> le chat s est en du du pression peigne peigne cheminée portail portail portail portail portail portail portail portail indépendant oiseaux oiseaux oiseaux oiseaux oiseaux oiseaux oiseaux oiseaux oiseaux oiseaux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>5. Questions:</b></h3>\n",
        "\n",
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 1 (5 points): </b><br>\n",
        "What do you think about our greedy decoding strategy? Base your answer on slides 87-95 from this <a href='https://nlp.stanford.edu/projects/nmt/Luong-Cho-Manning-NMT-ACL2016-v4.pdf'>presentation</a> (taken from this <a href='https://sites.google.com/site/acl16nmt/home'>ACL tutorial</a>).\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-4I1ROQnCIcZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Answer 1: </b><br>\n",
        "\n",
        "\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "t8j_ppwvJnWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greedy decoding strategy selects the next token by choosing the one with the highest probability at each step.  \n",
        "\n",
        "The advantages of this strategy are that it is:\n",
        "*   Simple - it can be implemented in only one line of code: `next_token = prediction.argmax()`\n",
        "*   Computationally and memory efficient - no track of multiple sequence hypotheses   \n",
        "\n",
        "On the other hand, greedy decoding is considered short-sighted as it only looks one token ahead and ignores how that choice will influence the rest of the sequence. Since it discards all but the most probable token at each step, it can eliminate slightly less probable candidate tokens (in the short term) that might have led to a more coherent and higher-quality full sequence. As a consequence, the model can get trapped in a local optimum rather than reaching the global one. This behavior illustrates the suboptimality problem, which is the main drawback of greedy decoding.\n",
        "\n",
        "In general, greedy decoding strategy is a good choice for simpler tasks (like this assignment) because of its simplicity and efficiency. However, when higher accuracy is needed, it’s better to use an alternative such as beam search, which considers multiple hypotheses and reduces the chance of getting stuck in a local optimum.\n"
      ],
      "metadata": {
        "id": "LWgQ_JnJ8c1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 2 (5 points): </b><br>\n",
        "What major problem do you observe with our translations?\n",
        "How could we remediate this issue? You may find inspiration from reading <a href='https://arxiv.org/abs/1508.04025'>[Luong et al., 2015]</a> and <a href='https://arxiv.org/abs/1601.04811'>[Tu et al., 2016]</a>.\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "z0m_Hw-NJopL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Answer 2: </b><br>\n",
        "\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "eExiju09Jhlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model performs well on simple inputs, but with more complex sequences, three major problems appear:\n",
        "\n",
        "1. Over-translation (Tu et al., 2016) – some words are translated multiple\n",
        "times, leading to unnecessary repetition.\n",
        "Example: \"*I love playing video games*\" -> *\"J’adore jouer à jeux jeux jeux vidéo*\". The word *\"games\"* (fr. *\"jeux\"*) is repeated multiple times.\n",
        "\n",
        "2. Under-translation (Tu et al., 2016) – some parts of the input are mistakenly untranslated.\n",
        "Example: *\"Help me pick out a tie to go with this suit!\"* -> *\"Aidez moi à chercher une cravate pour aller avec ceci\"*. The *\"pick out\"* is mistranslated as *\"chercher\"* (eng. *\"look for\"*/*\"find\"*) instead of *\"choisir\"* (eng. *\"to choose\"*). The word *\"suit\"* is not translated at all.\n",
        "\n",
        "3. Degeneration/hallucination (alongside under-translation) – the model produces irrelevant words not present in the input.\n",
        "Example: *\"The cat fell asleep in front of the fireplace\"* -> *\"Le chat s est en du du pression peigne peigne cheminée portail ... oiseaux ...\"*. Word *\"indépendant\"* (eng. *\"independent\"*) does not appear in source sentence.\n",
        "\n",
        "Per Luong et al. (2015) and Tu et al. (2016), these problems arrise because the model does not track past allignments-i.e. there is no track of attention history, causing the attentional decisions to be independent at each step.\n",
        "\n",
        "The remedy, per Luong et al. (2015), is the input-feeding approach in which attentional vectors\n",
        "are concatenated with inputs at the next time steps. By doing so, the model becomes fully aware of previous alignment choices.\n",
        "\n",
        "On the other hand, Tu et al. (2016) introduce a coverage vector that keeps a record of how much each source word has been translated to the target word, so the model knows what has already been translated. At each step, the coverage vector is appended to the attention features in order to keep track of the attention history. Additionally, they show that this method solves the under-translation of long sequences-i.e., the phenomenom where translations tend to be shorter as source sentences get longer. The problem is mitigated by coverage information, which pushes the attention to the untranslated parts of the source and prevents the early stop of decoding."
      ],
      "metadata": {
        "id": "YkhCfMMkZZIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 3 (5 points): </b><br>\n",
        "Write some code to visualize source/target alignments in the style of Fig. 3 in <a href='https://arxiv.org/abs/1409.0473'>[Bahdanau et al., 2014]</a> or Fig. 7 in <a href='https://arxiv.org/abs/1508.04025'>[Luong et al., 2015]</a>.\n",
        "Interpret your figures for some relevant examples (e.g. to illustrate adjective-noun inversion)\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "RawMHJkMJk-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Answer 3: </b><br>\n",
        "\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "-HY_LqQoJW_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(soruce_tokens, target_tokens, attention, title):\n",
        "    # Creation of a figure with heatmap\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    im = ax.imshow(attention, aspect=\"auto\", interpolation=\"nearest\", cmap=\"magma\")\n",
        "\n",
        "    # Set x and y ticks and labels\n",
        "    ax.set_xticks(np.arange(len(soruce_tokens)))\n",
        "    ax.set_yticks(np.arange(len(target_tokens)))\n",
        "    ax.set_xticklabels(soruce_tokens, fontsize=10)\n",
        "    ax.set_yticklabels(target_tokens, fontsize=10)\n",
        "\n",
        "    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n",
        "\n",
        "    ax.set_title(title, pad=16)\n",
        "    cbar = fig.colorbar(im, ax=ax)\n",
        "    cbar.set_label(\"Attention weight\", rotation=90, labelpad=10)\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def visualize(model, source_sentence):\n",
        "    # Preprocessing of the source sentence (the same way as in seq2seqModel class)\n",
        "    source_clean = source_sentence.lower().replace(\"'\", \" \").replace(\"-\", \" \")\n",
        "    source_tokens = word_tokenize(source_clean, model.source_language)\n",
        "\n",
        "    # Obtainment of model prediction\n",
        "    target_sentence, weights_list = model.predict(source_sentence)\n",
        "    target_tokens = target_sentence.split()\n",
        "\n",
        "    # Cut of the targe tokens if <EOS> or \".\" is present for visualization purposes\n",
        "    if \"<EOS>\" or \".\" in target_tokens:\n",
        "        candidates = []\n",
        "        if \"<EOS>\" in target_tokens:\n",
        "            candidates.append(target_tokens.index(\"<EOS>\")+1)\n",
        "        if \".\" in target_tokens:\n",
        "            candidates.append(target_tokens.index(\".\")+1)\n",
        "        cut_index = min(candidates)\n",
        "        target_tokens = target_tokens[:cut_index]\n",
        "        weights_list  = weights_list[:cut_index]\n",
        "\n",
        "    attention = np.array([np.squeeze(np.asarray(w)) for w in weights_list], dtype=np.float32)\n",
        "    attention = attention / attention.sum(axis=1, keepdims=True) + 1e-9\n",
        "\n",
        "    # Plot of the attention matrix\n",
        "    plot_attention(source_tokens, target_tokens, attention, title=source_sentence)\n"
      ],
      "metadata": {
        "id": "K4eaYTs3E4gQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will visualize source to target alignments on two sentences, each highlighting specific phenomenon(s):\n",
        "1. I have a blue car. (adjective-noun inversion)\n",
        "2. I do not eat food. (negation split; determiner; \"do\" absorption)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3Ay5gxUMSj2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(pretrained_model, \"I have a blue car.\")\n",
        "visualize(pretrained_model, \"I do not eat food.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m0Pb1850tJul",
        "outputId": "10dc8e06-263f-43e6-bfc7-b9d49c8792ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Figure 1*: Two sample alignments.The x-axis correspond to the words in the English sentence and y-axis correspond to the generated translation in French. Each *(i,j)* box represents the weight of *j*-th source word for the *i*-th target word."
      ],
      "metadata": {
        "id": "HVxmJvU7VCIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 1 shows the alignments on two sample translations."
      ],
      "metadata": {
        "id": "6iBinPe_cdGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Translation: *\"I have a blue car.\"->\"J'ai une voiture bleue.\"*  \n",
        "Main observation: The model captures the adjective-noun reordering - *\"blue car\"->\"voiture bleue\"*.\n",
        "The highest attention value for *\"bleue\"* is on *\"blue\"* column, while the highest attention value for *\"voiture\"* is on *\"car\"* column, even though the *\"bleue\"* comes after the noun in French, unlike in Enlish (i.e. highest attention values are off the main diagonal). The second highest values for *\"blue\"* and *\"car\"* are on *\"voiture\"* and *\"bleue\"* columns, respectively, which shows that the model treats this pair as a connected phrase.  \n",
        "Other observations: The rest of the tokens have their highest values on diagonal (*\"j\"->\"i\"*, *\"ai\"->\"have\"*, *\"une\"->\"a\"*, *\".\"->\".\"*), which shows the one-to-one mappings and translation with no reordering-i.e. the behavior we expected."
      ],
      "metadata": {
        "id": "FP5lm9POVsgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Translation: *\"I do not eat food.\"->\"Je ne mange pas de nourriture.\"*  \n",
        "Main observation: The model captures the negation split - *\"not\" -> \"ne ... pas\"*.\n",
        "The highest attention values for *\"ne\"* and *\"pas\"* are on *\"not\"* column. Even though English expresses negation with a single word *\"not\"*, while French uses *\"ne\"* with *\"pas\"*, the model was able to map one source token to two target tokens and make the translation correct.  \n",
        "Other observations:\n",
        "*  The source token *\"do\"*, an auxiliary verb in English, is used in the source sentence to support the negation. However, it's use in French is covered by *\"ne\"* + *verb* + *\"pas\"*, and therefore, it should not appear in the translation. Indeed, the outputs and the visualization show that the model understood this rule: *\"do\"* attracts low attention values from target tokens and so, it's absorbed in translation and doesn't surface in French sentence.\n",
        "*  In general, French nouns require a determiner. In our case, *\"food\"* was translated as *\"de nourriture\"*, which shows the model ability to insert a determiner before the noun and split and map one source token into two target ones, again. Consequently, the highest attention values for *\"de\"* and *\"nourriture\"* are on *\"food\"* column.\n",
        "* Tokens *\"je\"*, *\"mange\"* and *\".\"* have their highest  attention values for *\"I\"*, \"eat\"* and *\".\"*, respectively, and are mapped correctly.\n",
        "\n"
      ],
      "metadata": {
        "id": "-tHB7lunaljP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 4 (5 points): </b><br>\n",
        "What do you observe in the translations of the sentences below?\n",
        "What properties of language models does that illustrate?\n",
        "Read <a href='https://arxiv.org/abs/1802.05365'>[Peters et al., 2018]</a> and <a href='https://arxiv.org/abs/1810.04805'>[Devlin et al., 2018]</a>  to get some ideas.\n",
        "<ul>\n",
        "<b><h4><font color='red'>\n",
        "<li>$\\texttt{I did not mean to hurt you}$\n",
        "<li>$\\texttt{She is so mean}$\n",
        "</ul>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "_jRkSDMjFXLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Answer 4: </b><br>\n",
        "\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "4AyxolVhJU5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, let's evaluate the model one more time on these samples."
      ],
      "metadata": {
        "id": "p-zoBXxzxvvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = seq2seqModel.load(path_to_save_models + 'pretrained_moodle.pt')\n",
        "to_test = ['I did not mean to hurt you', 'She is so mean']\n",
        "for elt in to_test:\n",
        "    print('= = = = = \\n','%s -> %s' % (elt, pretrained_model.predict(elt)[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhU4R-kICWgE",
        "outputId": "fce9665f-35d7-471a-ae10-c2cffe302666"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max source index 5281\n",
            "source vocab size 5278\n",
            "max target index 7459\n",
            "target vocab size 7456\n",
            "= = = = = \n",
            " I did not mean to hurt you -> je n ai pas voulu intention de blesser blesser blesser blesser blesser blesser . blesser . blesser . . . . . . . . . . . . .\n",
            "= = = = = \n",
            " She is so mean -> elle est tellement méchant méchant . <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the discussion in Answer 2, we first observe that both translations exhibit over-translation. Words like *\"méchant\"* and *\"blesser\"* are unnecessarily repeated. Moreover, the word *\"mean\"* in the first sentence is translated as *\"voulu\"* (eng. *\"wanted\"*) + *\"intention\"* (eng. *\"intention\"*), which shows model's output redundancy. Furthermore, the word *\"méchant\"* should be translated as *\"méchante\"* in order to agree with *\"elle\"* (fem.).\n",
        "\n",
        "However, the key point in evaluation of these two samples is the use of the word *\"mean\"*. Although the model exhibits the above mentioned problems, its sense choice for the word *\"mean\"* is correct in both cases - *\"intend\"*/*\"want\"*, for the first sentence  vs. *\"unkind\"*/*\"bad\"*, for the second sentence. The model thus recognizes the polysemy-i.e. how the word's meaning and use may vary across linguistic contexts (Peters et al. 2018).\n",
        "\n",
        "Peters et. al (2018) and Devlin et al. (2018) address how a model can select the correct sense/use of a word depending on its context.\n",
        "\n",
        "Peters et al. (2018) introduce deep contextualized word representations. Each token in their work is represented as a function of the entire sentence, thereby allowing the model to capture both token's syntax and semantics information together with its context-dependent use.\n",
        "\n",
        "On the other hand, Devlin et al. (2018) achieve contextualization using multi-headed bidirectional self-attention. With the proposed attention mechanism, each token’s vector now depends on both left and right context, which enables effective word sense disambiguation.\n"
      ],
      "metadata": {
        "id": "1nvTMNz9Cx1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>6. Appendix:</b>\n",
        "<h4><b>6.1. GRU unit:</b></h4>\n",
        "<p style=\"text-align: justify;\">\n",
        "As shown in Fig. 3, the GRU unit <a href='https://arxiv.org/abs/1406.1078'>[Cho et al., 2014]</a> is a simple RNN unit with two gates (reset and update):\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{reset gate:}~~r_{t} = \\sigma \\big(U_{r}x_{t} + W_{r}h_{t-1} + b_r\\big)\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{update gate:}~~z_{t} = \\sigma \\big(U_{z}x_{t} + W_{z}h_{t-1} + b_z\\big)\n",
        "\\end{equation}\n",
        "\n",
        "The candidate hidden state is computed as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{h}_{t} = \\mathrm{tanh} \\big(U_{h}x_{t} + W_{h} (r_t \\circ h_{t-1}) + b_h\\big)\n",
        "\\end{equation}\n",
        "\n",
        "<center>\n",
        "<img width='500px' src='https://1drv.ms/i/c/ae69638675180117/UQQXARh1hmNpIICuuYQBAAAAAEpvFJzwgjB2a3Y?width=703&height=489' />\n",
        "<br>\n",
        "<b>Figure 3:</b> GRU unit. Taken from <a href='http://colah.github.io/posts/2015-08-Understanding-LSTMs/'>Chris Olah's blog</a>.<br>\n",
        "</center>\n",
        "\n",
        "The reset gate determines how much of the information from the previous time steps (stored in $h_{t-1}$) should be discarded.\n",
        "The new hidden state is finally obtained by linearly interpolating between the previous hidden state and the candidate one:\n",
        "\n",
        "\\begin{equation}\n",
        "h_{t} = (1-z_t) \\circ {h}_{t-1} + z_t \\circ \\hat{h}_{t}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "Z--prNCiJ0Un"
      }
    }
  ]
}